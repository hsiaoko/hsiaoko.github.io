---
title: "Distributed memory code generation for mixed irregular/regular computations"
collection: publications
permalink: /publication/2015-ppopp
date: 2015-01-01
venue: 'ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP)'
paperurl: 'https://dl.acm.org/authorize?N658061'
citation: 'Mahesh Ravishankar, Roshan Dathathri, Venmugil Elango, Louis-Noel Pouchet, J Ramanujam, Atanas Rountev, P Sadayappan, “Distributed memory code generation for mixed irregular/regular computations,” Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), January 2015.'
---
[(Download publication here)](https://www.cs.utexas.edu/~roshan/distributed_mixed_irregular_ppopp15.pdf)

Read about our work in the [R&D magazine article](https://www.rdmag.com/article/2019/04/determining-importance-connections-unstructured-data)

### Abstract

Many applications feature a mix of irregular and regular computational structures. For example, codes using adaptive mesh refinement (AMR) typically use a collection of regular blocks, where the number of blocks and the relationship between blocks is irregular. The computational structure in such applications generally involves regular (affine) loop computations within some number of innermost loops, while outer loops exhibit irregularity due to data-dependent control flow and indirect array access patterns. Prior approaches to distributed memory parallelization do not handle such computations effectively. They either target loop nests that are completely affine using polyhedral frameworks, or treat all loops as irregular. Consequently, the generated distributed memory code contains artifacts that disrupt the regular nature of previously affine innermost loops of the computation. This hampers subsequent optimizations to improve on-node performance. We propose a code generation framework that can effectively transform such applications for execution on distributed memory systems. Our approach generates distributed memory code which preserves program properties that enable subsequent polyhederal optimizations. Simultaneously, it addresses a major memory bottleneck of prior techniques that limits the scalability of the generated code. The effectiveness of the proposed framework is demonstrated on computations that are mixed regular/irregular, completely regular, and completely irregular.


